This project demonstrates the effectiveness of prompt-based learning using Hugging Face transformer models for bug severity classification.

Zero-shot learning showed that large language models can make reasonable predictions even without prior examples, especially for clear and severe cases.

Few-shot learning significantly improved accuracy by providing contextual examples, helping the model understand the relationship between bug descriptions and severity levels more effectively.

Overall, few-shot prompting consistently outperformed zero-shot prompting, showing that minimal labeled context can meaningfully enhance model reasoning without requiring retraining or fine-tuning.

This experiment highlights how LLMs can perform classification tasks through intelligent prompting, offering a lightweight and flexible alternative to traditional supervised approaches â€” particularly useful when labeled data is limited.
